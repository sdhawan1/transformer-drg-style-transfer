{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Head_selection.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jMjcFHyhi5vI","colab_type":"text"},"source":["# Head Selection\n","**_BERT_** is a **_Multi-layer_ _Multi-Head_** Transformer architecture. As discuss in many of the current reseachers, different Attention heads captures different lingustic patterns. For a better deletion of words using Attention mechanism we need to choose a head which **captures pattern useful for classification.**\n","\n","To do this we are using a Brute force mechanism to seach through all the possible heads. We are deleting TopK words attended by different heads from the sentence and measuring the new classification score. In case of sentiments, removing sentiments related words makes the sentence neutral. The heads are sorted by the amount to which it is able to make the sentences from dev set to Neutral."]},{"cell_type":"code","metadata":{"id":"RvS6rEFSkNsE","colab_type":"code","outputId":"e5a93005-3aff-4d93-f66d-122704839247","executionInfo":{"status":"ok","timestamp":1590977555228,"user_tz":420,"elapsed":20259,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","#drive.mount('/content/gdrive')\n","\n","drive.mount(\"/content/gdrive\", force_remount=False)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wIDdP_itk-va","colab_type":"code","outputId":"c1a2e0f8-bfe7-4de0-d0d9-0daea0575007","executionInfo":{"status":"ok","timestamp":1590977561829,"user_tz":420,"elapsed":3487,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["## specify hardware.\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I7997Dg3ZI3W","colab_type":"code","outputId":"e807f922-90bd-41f8-da02-95f6e6261875","executionInfo":{"status":"ok","timestamp":1590201506231,"user_tz":420,"elapsed":1043,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import sys\n","print(sys.path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B-4n04ffi5vL","colab_type":"code","outputId":"908c4afc-5d2e-40fc-93c3-51aff91b2dd2","executionInfo":{"status":"ok","timestamp":1590977582009,"user_tz":420,"elapsed":14480,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import csv\n","import logging\n","import os\n","import random\n","import sys\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm, trange\n","\n","#load the forked \"pretrained_bert_model\" settings included in the drg repo (use this for bertviz stuff too...)\n","drg_repo_path = '/content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer'\n","if not drg_repo_path in sys.path:\n","  sys.path.append(drg_repo_path)\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n","#from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear #(deprecated)\n","\n","from bertviz.bertviz import attention, visualization\n","from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.INFO)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CVFL9_Tyi5vV","colab_type":"code","outputId":"5136ebd4-c6c1-4d8d-b222-cfa8077c367a","executionInfo":{"status":"ok","timestamp":1590201519240,"user_tz":420,"elapsed":954,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["logger = logging.getLogger(__name__)\n","bert_classifier_model_dir = \"/content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer/bert_classifier\" ## Path of BERT classifier model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["05/23/2020 02:38:38 - INFO - __main__ -   device: cuda, n_gpu 1\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mc5qgTF7i5vh","colab_type":"code","outputId":"599301c2-141f-483b-cf93-3e96b9d83b91","executionInfo":{"status":"ok","timestamp":1590201542926,"user_tz":420,"elapsed":8669,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## Model for performing Classification\n","model_cls = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","model_cls.to(device)\n","model_cls.eval()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["05/23/2020 02:38:54 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer/bert_classifier\n","05/23/2020 02:38:54 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","05/23/2020 02:39:02 - INFO - bertviz.bertviz.pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Gnx68J98i5vo","colab_type":"code","outputId":"7c63f5fb-251d-4992-a512-39e904ee1e40","executionInfo":{"status":"ok","timestamp":1590201568393,"user_tz":420,"elapsed":2967,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## Model to get the attention weights of all the heads\n","model = BertModel.from_pretrained(bert_classifier_model_dir)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","model.to(device)\n","model.eval()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["05/23/2020 02:39:25 - INFO - bertviz.bertviz.pytorch_pretrained_bert.modeling -   loading archive file /content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer/bert_classifier\n","05/23/2020 02:39:25 - INFO - bertviz.bertviz.pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","05/23/2020 02:39:27 - INFO - bertviz.bertviz.pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"wjN1Nym9i5vt","colab_type":"code","colab":{}},"source":["max_seq_len=70 # Maximum sequence length \n","sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxpbhyRYi5v0","colab_type":"code","colab":{}},"source":["def run_multiple_examples(input_sentences, bs=32):\n","    \"\"\"\n","    This fucntion returns classification predictions for batch of sentences.\n","    input_sentences: list of strings\n","    bs : batch_size : int\n","    \"\"\"\n","    \n","    ## Prepare data for classification\n","    ids = []\n","    segment_ids = []\n","    input_masks = []\n","    pred_lt = []\n","    for sen in input_sentences:\n","        text_tokens = tokenizer.tokenize(sen)\n","        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n","        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        input_mask = [1] * len(temp_ids)\n","        segment_id = [0] * len(temp_ids)\n","        padding = [0] * (max_seq_len - len(temp_ids))\n","\n","        temp_ids += padding\n","        input_mask += padding\n","        segment_id += padding\n","        \n","        ids.append(temp_ids)\n","        input_masks.append(input_mask)\n","        segment_ids.append(segment_id)\n","    \n","    ## Convert input lists to Torch Tensors\n","    ids = torch.tensor(ids)\n","    segment_ids = torch.tensor(segment_ids)\n","    input_masks = torch.tensor(input_masks)\n","    \n","    steps = len(ids) // bs\n","    \n","    for i in range(steps+1):\n","        if i == steps:\n","            temp_ids = ids[i * bs : len(ids)]\n","            temp_segment_ids = segment_ids[i * bs: len(ids)]\n","            temp_input_masks = input_masks[i * bs: len(ids)]\n","        else:\n","            temp_ids = ids[i * bs : i * bs + bs]\n","            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n","            temp_input_masks = input_masks[i * bs: i * bs + bs]\n","        \n","        temp_ids = temp_ids.to(device)\n","        temp_segment_ids = temp_segment_ids.to(device)\n","        temp_input_masks = temp_input_masks.to(device)\n","        \n","        with torch.no_grad():\n","            preds = sm(model_cls(temp_ids, temp_segment_ids, temp_input_masks))\n","        pred_lt.extend(preds.tolist())\n","    \n","    return pred_lt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGJOvB90i5v9","colab_type":"code","colab":{}},"source":["def read_file(path,size):\n","    with open(path) as fp:\n","        data = fp.read().splitlines()[:size]\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQ4inPfZi5wB","colab_type":"code","colab":{}},"source":["def get_attention_for_batch(input_sentences, bs=32):\n","    \"\"\"\n","    This function calculates attention weights of all the heads and\n","    returns it along with the encoded sentence for further processing.\n","    \n","    input sentence: list of strings\n","    bs : batch_size\n","    \"\"\"\n","    \n","    ## Preprocessing for BERT \n","    ids = []\n","    segment_ids = []\n","    input_masks = []\n","    pred_lt = []\n","    ids_for_decoding = []\n","    for sen in input_sentences:\n","        text_tokens = tokenizer.tokenize(sen)\n","        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n","        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        input_mask = [1] * len(temp_ids)\n","        segment_id = [0] * len(temp_ids)\n","        padding = [0] * (max_seq_len - len(temp_ids))\n","        \n","        ids_for_decoding.append(tokenizer.convert_tokens_to_ids(tokens))\n","        temp_ids += padding\n","        input_mask += padding\n","        segment_id += padding\n","        \n","        ids.append(temp_ids)\n","        input_masks.append(input_mask)\n","        segment_ids.append(segment_id)\n","    ## Convert the list of int ids to Torch Tensors\n","    ids = torch.tensor(ids)\n","    segment_ids = torch.tensor(segment_ids)\n","    input_masks = torch.tensor(input_masks)\n","    \n","    steps = len(ids) // bs\n","    \n","    for i in trange(steps+1):\n","        if i == steps:\n","            temp_ids = ids[i * bs : len(ids)]\n","            temp_segment_ids = segment_ids[i * bs: len(ids)]\n","            temp_input_masks = input_masks[i * bs: len(ids)]\n","        else:\n","            temp_ids = ids[i * bs : i * bs + bs]\n","            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n","            temp_input_masks = input_masks[i * bs: i * bs + bs]\n","        \n","        temp_ids = temp_ids.to(device)\n","        temp_segment_ids = temp_segment_ids.to(device)\n","        temp_input_masks = temp_input_masks.to(device)\n","        \n","        with torch.no_grad():\n","            ##DEBUG\n","            '''\n","            ret = model(temp_ids, temp_segment_ids, temp_input_masks)\n","            attn = ret[-1]\n","            print(ret)\n","            print(attn)\n","            return attn, None\n","            '''\n","            _, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n","            \n","        \n","        # Add all the Attention Weights to CPU memory\n","        # Attention weights for each layer is stored in a dict 'attn_prob'\n","        for k in range(12):\n","            attn[k]['attn_probs'] = attn[k]['attn_probs'].to('cpu')\n","        \n","        '''\n","        attention weights are stored in this way:\n","        att_lt[layer]['attn_probs']['input_sentence']['head']['length_of_sentence']\n","        '''\n","        # Concate Attention weights for all the examples in the list att_lt[layer_no]['attn_probs']\n","        \n","        if i == 0:\n","            att_lt = attn\n","            heads = len(att_lt)\n","        else:\n","            for j in range(heads):\n","                att_lt[j]['attn_probs'] = torch.cat((att_lt[j]['attn_probs'],attn[j]['attn_probs']),0)\n","        \n","    \n","    return att_lt, ids_for_decoding"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGV5KeuCi5wF","colab_type":"code","colab":{}},"source":["def process_sentences(input_sentences, att, decoding_ids, threshold=0.25):\n","    \"\"\"\n","    This function processes each input sentence by removing the top tokens defined threshold value.\n","    Each sentence is processed for each head.\n","    \n","    input_ids: list of strings\n","    decoding_ids: indexed input_sentnces thus len(input_sentences) == len(decoding_ids)\n","    threshold: Percentage of the top indexes to be removed\n","    \"\"\"\n","    # List of None of num_of_layers * num_of_heads to save the results of each head for input_sentences\n","    \n","    lt = [None for x in range(len(att) * len(att[0]['attn_probs'][0]))]\n","    #print(len(lt))\n","    \n","    inx = 0\n","    for i in trange(len(att)): #  For all the layers\n","        for j in range(len(att[i]['attn_probs'][0])): # For all the heads in the ith Layer\n","            processed_sen = [None for q in decoding_ids] # List of len(decoding_ids)\n","            for k in range(len(input_sentences)): # For all the senteces \n","                _, topi = att[i]['attn_probs'][k][j][0].topk(len(decoding_ids[k])) # Get top attended ids\n","                topi = topi.tolist()\n","                topi = topi[:int(len(topi) * threshold)] \n","                ## Decode the sentece after removing the topk indexes\n","                final_indexes = []\n","                count = 0\n","                count1 = 0\n","                tokens = [\"[CLS]\"] + tokenizer.tokenize(input_sentences[k]) + [\"[SEP]\"]\n","                while count < len(decoding_ids[k]):\n","                    if count in topi: # Remove index if present in topk\n","                        while (count + count1 + 1) < len(decoding_ids[k]):\n","                            if \"##\" in tokens[count + count1 + 1]:\n","                                count1 += 1\n","                            else:\n","                                break\n","                        count += count1\n","                        count1 = 0\n","                    else: # Else add to the decoded sentence\n","                        final_indexes.append(decoding_ids[k][count])\n","                    count += 1\n","                tmp = tokenizer.convert_ids_to_tokens(final_indexes) # Convert ids to token\n","                # Convert toknes to sentence\n","                processed_sen[k] = \" \".join(tmp).replace(\" ##\", \"\").replace(\"[CLS]\",\"\").replace(\"[SEP]\",\"\").strip()\n","            lt[inx] = processed_sen # Store sentences for inxth head\n","            inx += 1\n","    \n","    return lt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"77gvhmrCi5wM","colab_type":"code","colab":{}},"source":["def get_block_head(processed_sentence_list, lmbd = 0.1):\n","    \"\"\"\n","    This function calculate classification scores for sentences generated by each head\n","    and sort them from best to worst.\n","    score = min(pred) + lmbd / max(pred) + lmbd, lmbd is smoothing param\n","    pred is list of probability score for each class, for best case pred = [0.5, 0.5] ==> score = 1\n","    \n","    it returns sorted list of (Layer, Head, Score)\n","    \"\"\"\n","    scores = {}\n","    #scores_1 = {}\n","    for i in trange(len(processed_sentence_list)): # sentences by each head\n","        pred = np.array(run_multiple_examples(processed_sentence_list[i]))\n","        scores[i] = np.mean([(min(x[0], x[1])+lmbd)/(max(x[0], x[1])+lmbd) for x in pred])\n","        #scores_1[i] = np.mean([abs(max(x[0],x[1]) - min(x[0],x[1])) for x in pred])\n","    temp = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n","    #temp1 = sorted(scores_1.items(), key=lambda kv: kv[1], reverse=False)\n","    score_lt = [(x // 12, x - (12 * (x // 12)),y) for x,y in temp]\n","    #score1_lt = [(x // 12, x - (12 * (x // 12)),y) for x,y in temp1]\n","    return score_lt  #score1_lt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IUUo8CAi5wS","colab_type":"code","colab":{}},"source":["pos_examples_file = \"/content/gdrive/My Drive/humor_style_transfer/style-transfer-data/Sentiment-and-Style-Transfer/data/yelp/sentiment.dev.1\" #sentiment_dev_1.txt\n","neg_examples_file = \"/content/gdrive/My Drive/humor_style_transfer/style-transfer-data/Sentiment-and-Style-Transfer/data/yelp/sentiment.dev.0\" #sentiment_dev_0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ziLEUX4Hi5wW","colab_type":"code","colab":{}},"source":["'''\n","100 examples from each class worked good, the bottlenack is the run_multiple_examples() function,\n","with higher memory (either with cpu of gpu) one can reduce the processing time by incresing batch_size.\n","With batch_size of 32 it takes around 24 mins for 100 example on cpu.\n","'''\n","pos_data = read_file(pos_examples_file,100)\n","neg_data = read_file(neg_examples_file,100)\n","data = pos_data + neg_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"So-CXiC1i5wc","colab_type":"code","outputId":"297c0aed-5a58-4005-f119-b9f920df0630","executionInfo":{"status":"ok","timestamp":1590201629636,"user_tz":420,"elapsed":13803,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(pos_data), len(neg_data), len(data))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100 100 200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBqi8B3ji5wi","colab_type":"code","outputId":"26a4332b-23dd-42c4-9807-8c1c52e7cc2a","executionInfo":{"status":"ok","timestamp":1590201642755,"user_tz":420,"elapsed":2564,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["att, decoding_ids = get_attention_for_batch(data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 7/7 [00:01<00:00,  3.98it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"evNTmDiHi5wn","colab_type":"code","outputId":"cc241bfd-f357-4729-ee9e-297202ff0cbe","executionInfo":{"status":"ok","timestamp":1590201650641,"user_tz":420,"elapsed":4173,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sen_list = process_sentences(data, att, decoding_ids)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 12/12 [00:03<00:00,  3.39it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vlZqsOdCi5wt","colab_type":"code","outputId":"bd10bd6c-e761-4e54-9c84-d8e4ed8a7d19","executionInfo":{"status":"ok","timestamp":1590201811182,"user_tz":420,"elapsed":145539,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["scores = get_block_head(sen_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 144/144 [02:24<00:00,  1.00s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eAGwUDOJi5wz","colab_type":"code","outputId":"643b5b76-1457-4ad9-ef5b-3b1774ce201c","executionInfo":{"status":"ok","timestamp":1590201815780,"user_tz":420,"elapsed":897,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["scores"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(9, 6, 0.09092394134003573),\n"," (11, 4, 0.09092393797420964),\n"," (9, 3, 0.09092393479885129),\n"," (10, 2, 0.0909239338813776),\n"," (9, 1, 0.09092393035794329),\n"," (7, 7, 0.0909239295233948),\n"," (1, 7, 0.0909239289276586),\n"," (4, 10, 0.09092392872548193),\n"," (8, 4, 0.09092392825798164),\n"," (8, 3, 0.09092392745210554),\n"," (9, 9, 0.0909239271045643),\n"," (7, 11, 0.09092392687484012),\n"," (9, 10, 0.09092392678058538),\n"," (11, 8, 0.09092392659921153),\n"," (1, 3, 0.09092392619748267),\n"," (10, 9, 0.09092392481543664),\n"," (1, 10, 0.09092392446571361),\n"," (5, 10, 0.09092392255968174),\n"," (6, 9, 0.09092392151515344),\n"," (10, 6, 0.09092392044195999),\n"," (3, 5, 0.09092392017497619),\n"," (2, 10, 0.09092391986368512),\n"," (7, 3, 0.09092391978330015),\n"," (2, 2, 0.09092391804914574),\n"," (2, 6, 0.09092391767189884),\n"," (0, 2, 0.09092391762965395),\n"," (4, 3, 0.09092391725257241),\n"," (9, 0, 0.09092391620255619),\n"," (6, 1, 0.09092391582851811),\n"," (11, 5, 0.09092391528278738),\n"," (7, 6, 0.09092391436228194),\n"," (1, 6, 0.09092391430282813),\n"," (7, 9, 0.09092391422122698),\n"," (10, 0, 0.09092391403181313),\n"," (3, 0, 0.09092391356805907),\n"," (8, 11, 0.09092391317961265),\n"," (10, 1, 0.09092391297863436),\n"," (0, 5, 0.09092391260233872),\n"," (1, 4, 0.09092391222218131),\n"," (3, 11, 0.09092391192221783),\n"," (2, 5, 0.09092391164751458),\n"," (4, 2, 0.09092391138446225),\n"," (4, 9, 0.09092391092862961),\n"," (9, 11, 0.0909239109112167),\n"," (1, 5, 0.09092391032386443),\n"," (5, 6, 0.09092390968390841),\n"," (6, 11, 0.09092390952832341),\n"," (10, 5, 0.09092390844163954),\n"," (2, 8, 0.09092390717056731),\n"," (9, 2, 0.09092390565819132),\n"," (2, 11, 0.09092390513266896),\n"," (4, 8, 0.09092390492760774),\n"," (10, 4, 0.09092390405374016),\n"," (5, 3, 0.09092390335556243),\n"," (6, 2, 0.09092390329240367),\n"," (6, 3, 0.09092390305712346),\n"," (1, 9, 0.09092390209797512),\n"," (2, 4, 0.0909239016737387),\n"," (7, 8, 0.09092390127240932),\n"," (3, 3, 0.09092390110661644),\n"," (5, 5, 0.09092390057105477),\n"," (6, 10, 0.09092390025066983),\n"," (8, 0, 0.09092389925838645),\n"," (3, 9, 0.09092389911303336),\n"," (0, 7, 0.09092389908839055),\n"," (10, 10, 0.09092389902444814),\n"," (1, 8, 0.0909238989102285),\n"," (2, 1, 0.0909238986915808),\n"," (5, 11, 0.09092389868038563),\n"," (3, 1, 0.09092389839122506),\n"," (11, 7, 0.09092389787276796),\n"," (3, 8, 0.0909238977364673),\n"," (1, 2, 0.0909238969252504),\n"," (10, 7, 0.09092389687569373),\n"," (4, 0, 0.09092389537363708),\n"," (5, 2, 0.09092389511568733),\n"," (11, 6, 0.09092389373412481),\n"," (8, 6, 0.09092389358835996),\n"," (2, 9, 0.09092389343157033),\n"," (6, 8, 0.09092389290519114),\n"," (0, 0, 0.09092389276187518),\n"," (2, 7, 0.09092389163820432),\n"," (8, 9, 0.09092389117251151),\n"," (3, 2, 0.09092389114644409),\n"," (10, 11, 0.0909238904535398),\n"," (5, 1, 0.09092388990088558),\n"," (2, 3, 0.09092388984040248),\n"," (11, 1, 0.09092388938222161),\n"," (10, 3, 0.0909238869133442),\n"," (11, 10, 0.09092388614130165),\n"," (2, 0, 0.09092388585722644),\n"," (0, 6, 0.09092388582432073),\n"," (0, 11, 0.09092388531685397),\n"," (3, 7, 0.09092388406735495),\n"," (7, 1, 0.09092388389299731),\n"," (1, 11, 0.09092388228521107),\n"," (4, 7, 0.09092388208579248),\n"," (0, 1, 0.09092388158385459),\n"," (3, 10, 0.09092388091303366),\n"," (3, 4, 0.0909238807245146),\n"," (0, 10, 0.09092388048856107),\n"," (8, 7, 0.09092388019526126),\n"," (11, 3, 0.09092387934651207),\n"," (4, 6, 0.09092387603110481),\n"," (4, 4, 0.09092387495252019),\n"," (8, 1, 0.09092387463917662),\n"," (5, 4, 0.09092386868516165),\n"," (7, 2, 0.09092386845758091),\n"," (11, 0, 0.09092386749620665),\n"," (3, 6, 0.09092386733867677),\n"," (7, 0, 0.09092386721875073),\n"," (7, 4, 0.09092386552098292),\n"," (4, 5, 0.09092386419504889),\n"," (4, 11, 0.09092386286252889),\n"," (11, 2, 0.09092385947448775),\n"," (0, 3, 0.09092385943716107),\n"," (9, 4, 0.09092385897856424),\n"," (5, 0, 0.09092385886589575),\n"," (6, 5, 0.09092385875301773),\n"," (6, 6, 0.09092385865315791),\n"," (0, 8, 0.09092385652218474),\n"," (0, 4, 0.09092385548276834),\n"," (6, 7, 0.09092385484861289),\n"," (1, 0, 0.09092385352664496),\n"," (7, 5, 0.09092385348399425),\n"," (6, 4, 0.09092385334291819),\n"," (8, 2, 0.09092385163925154),\n"," (5, 8, 0.09092384737328978),\n"," (7, 10, 0.09092384649868165),\n"," (5, 7, 0.09092384415133463),\n"," (1, 1, 0.09092384353416202),\n"," (9, 7, 0.0909238430814046),\n"," (6, 0, 0.09092384257206636),\n"," (4, 1, 0.09092383883105759),\n"," (11, 11, 0.09092383779836326),\n"," (9, 5, 0.09092383773267035),\n"," (8, 8, 0.09092383745226147),\n"," (8, 10, 0.09092383345207945),\n"," (9, 8, 0.09092382455440066),\n"," (11, 9, 0.09092382297402382),\n"," (8, 5, 0.0909238228572565),\n"," (5, 9, 0.09092382069669157),\n"," (0, 9, 0.09092381154895587),\n"," (10, 8, 0.09092379761126672)]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"5PK3JR_ci5w2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}