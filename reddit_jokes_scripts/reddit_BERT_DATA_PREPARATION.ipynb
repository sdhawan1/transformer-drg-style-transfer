{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"reddit_BERT_DATA_PREPARATION.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OOjYTEnOHZY2","colab_type":"code","outputId":"49061de1-6e77-495d-cdeb-638ca1672e2f","executionInfo":{"status":"ok","timestamp":1591320204047,"user_tz":420,"elapsed":24050,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","#drive.mount('/content/gdrive')\n","\n","drive.mount(\"/content/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2x6cuLESqgAv","colab_type":"code","outputId":"83b8c124-1332-492a-a66a-84caa3aeb332","executionInfo":{"status":"ok","timestamp":1591320223566,"user_tz":420,"elapsed":1390,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import sys\n","print(sys.path)\n","#from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE"],"execution_count":2,"outputs":[{"output_type":"stream","text":["['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"18y9m_ri-TaQ","colab_type":"code","outputId":"984dcb80-c16e-41b9-8a8d-4cd4f7d47ad7","executionInfo":{"status":"ok","timestamp":1591320265027,"user_tz":420,"elapsed":35441,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import csv\n","import logging\n","import os\n","import random\n","import sys\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm, trange\n","\n","#load the forked \"pretrained_bert_model\" settings included in the drg repo (use this for bertviz stuff too...)\n","drg_repo_path = '/content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer'\n","if not drg_repo_path in sys.path:\n","  sys.path.append(drg_repo_path)\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n","#from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear #(NOTE: IN THE NEWEST VERSION, 'WARMUP_LINEAR' = ARG FOR BERTADAM)\n","\n","# this part was misbehaving in earlier versions.\n","from bertviz.bertviz import attention, visualization\n","from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"79dO4ZHi-Taa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"02c82038-b412-481c-becf-f92eeb619413","executionInfo":{"status":"ok","timestamp":1591320289716,"user_tz":420,"elapsed":1486,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["logger = logging.getLogger(__name__)\n","## Path of recently trained BERT classifier model (customize)\n","bert_classifier_model_dir = \"/content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer/reddit_jokes_scripts/bert_classifier\" \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))\n","print(device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OlxUXJLj-Tak","colab_type":"code","colab":{}},"source":["# file paths\n","data_dir = '/content/gdrive/My Drive/humor_style_transfer/reddit_jokes/joke-dataset/style_trans_preprocessing'\n","train_0 = os.path.join(data_dir ,\"./jokes.train.0\")\n","train_1 = os.path.join(data_dir,\"./jokes.train.1\")\n","test_0 = os.path.join(data_dir,\"./jokes.test.0\")\n","test_1 = os.path.join(data_dir,\"./jokes.test.1\")\n","dev_0 = os.path.join(data_dir,\"./jokes.dev.0\")\n","dev_1 = os.path.join(data_dir,\"./jokes.dev.1\")\n","#reference_0 = os.path.join(data_dir,\"./reference.0\")\n","#reference_1 = os.path.join(data_dir,\"./reference.1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwCOW9eX-Taq","colab_type":"code","colab":{}},"source":["# file paths\n","data_dir = '/content/gdrive/My Drive/humor_style_transfer/reddit_jokes/joke-dataset/style_trans_preprocessing'\n","train_0_out = os.path.join(data_dir ,\"./processed_files_with_bert_with_best_head/jokes.train.0\")\n","train_1_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/jokes.train.1\")\n","test_0_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/jokes.test.0\")\n","test_1_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/jokes.test.1\")\n","dev_0_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/jokes.dev.0\")\n","dev_1_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/jokes.dev.1\")\n","reference_0_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/reference.0\")\n","reference_1_out = os.path.join(data_dir,\"./processed_files_with_bert_with_best_head/reference.1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvdP_xyE-Taw","colab_type":"code","colab":{}},"source":["## Model for performing Classification [WHY DO I NEED THIS CELL??? GOING TO TRY WITHOUT THIS...] Update: it was completely unnecessary.\n","\n","#[use this after pretrained model found?]\n","#model_cls = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2) \n","\n","#I think this is downloading bert model - save it later.\n","model_cls = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","model_cls.to(device)\n","model_cls.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXfyUn-3-Ta3","colab_type":"code","outputId":"ac11289e-877b-4eeb-b54b-d2a34fd05cb0","executionInfo":{"status":"ok","timestamp":1591320392060,"user_tz":420,"elapsed":20219,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## Model to get the attention weights of all the heads\n","\n","# [customize: use the recently trained bert model.]\n","model = BertModel.from_pretrained(bert_classifier_model_dir)\n","#model = BertModel.from_pretrained('bert-base-uncased')\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","model.to(device)\n","model.eval()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 266322.98B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Q-yE15HB-Ta8","colab_type":"code","colab":{}},"source":["max_seq_len=40 # Maximum sequence length \n","sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVhKt-A3-TbB","colab_type":"code","colab":{}},"source":["common_words=['is','are','was','were','has','have','had','a','an','the','this','that','these','those','there','how','i','we',\n","             'he','she','it','they','them','their','his','him','her','us','our', 'and','in','my','your','you', 'will', 'shall']\n","common_words_tokens = tokenizer.convert_tokens_to_ids(common_words)\n","not_to_remove_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\",\"[SEP]\", \".\", \"?\", \"!\"])\n","not_to_remove_ids += common_words_tokens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YeiKl0q-TbF","colab_type":"code","colab":{}},"source":["def read_file(file_path):\n","    with open(file_path) as fp:\n","        data = fp.read().splitlines()\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OP1rAcjw-TbK","colab_type":"code","colab":{}},"source":["def create_output_file(original_sentences,processed_sentences, output_file, sentiment=\"<POS>\"):\n","    with open(output_file,\"w\") as fp:\n","        for sen1,sen2 in zip(original_sentences,processed_sentences):\n","            if sen1 != None and sen2 != None:\n","                str1 = sentiment + \" <CON_START> \" + sen2 + \" <START> \" + sen1 + \" <END>\\n\"\n","                fp.write(str1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-pkK_yJ-TbO","colab_type":"code","colab":{}},"source":["#call from lower part: #create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")\n","def create_ref_output_file(processed_sentences, output_file, sentiment=\"<POS>\"):\n","    with open(output_file,\"w\") as fp:\n","        for sen in tqdm(processed_sentences):\n","            if sen != None:\n","                str1 = sentiment + \" <CON_START> \" + sen + \" <START>\\n\"\n","                fp.write(str1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f9itaVL-TbT","colab_type":"code","colab":{}},"source":["def concate_files(inp_files, out_files):\n","    with open(out_files,\"w\") as fp:\n","        for file in inp_files:\n","            with open(file) as f:\n","                for line in f:\n","                    fp.write(line)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G6riNArw-TbY","colab_type":"code","colab":{}},"source":["def run_attn_examples(input_sentences, layer, head, bs=128):\n","    \"\"\"\n","    Returns Attention weights for selected Layer and Head along with ids and tokens\n","    of the input_sentence\n","    \"\"\"\n","    ids = []\n","    ids_to_decode = [None for k in range(len(input_sentences))]\n","    tokens_to_decode = [None for k in range(len(input_sentences))]\n","    segment_ids = []\n","    input_masks = []\n","    attention_weights = [None for z in input_sentences]\n","    ## BERT pre-processing\n","    for j,sen in enumerate(tqdm(input_sentences)):\n","        \n","        text_tokens = tokenizer.tokenize(sen)\n","        if len(text_tokens) >= max_seq_len-2:\n","            text_tokens = text_tokens[:max_seq_len-4]\n","        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n","        tokens_to_decode[j] = tokens\n","        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        ids_to_decode[j] = temp_ids\n","        input_mask = [1] * len(temp_ids)\n","        segment_id = [0] * len(temp_ids)\n","        padding = [0] * (max_seq_len - len(temp_ids))\n","        \n","        \n","        temp_ids += padding\n","        input_mask += padding\n","        segment_id += padding\n","        \n","        ids.append(temp_ids)\n","        input_masks.append(input_mask)\n","        segment_ids.append(segment_id)\n","    \n","    # Convert Ids to Torch Tensors\n","    ids = torch.tensor(ids) \n","    segment_ids = torch.tensor(segment_ids)\n","    input_masks = torch.tensor(input_masks)\n","    \n","    steps = len(ids) // bs\n","    \n","    for i in trange(steps+1):\n","        if i == steps:\n","            temp_ids = ids[i * bs : len(ids)]\n","            temp_segment_ids = segment_ids[i * bs: len(ids)]\n","            temp_input_masks = input_masks[i * bs: len(ids)]\n","        else:\n","            temp_ids = ids[i * bs : i * bs + bs]\n","            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n","            temp_input_masks = input_masks[i * bs: i * bs + bs]\n","        \n","        temp_ids = temp_ids.to(device)\n","        temp_segment_ids = temp_segment_ids.to(device)\n","        temp_input_masks = temp_input_masks.to(device)\n","        with torch.no_grad():\n","          _, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n","          #WARNING: changed model; produces 2 outputs not 3 (???)\n","            ## what does the below do ??\n","             #_, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n","        # Concate Attention weights\n","        for j in range(len(attn[layer]['attn_probs'])):\n","            attention_weights[i * bs + j] = (attn[layer]['attn_probs'][j][head][0]).to('cpu')\n","    \n","    return attention_weights, ids_to_decode, tokens_to_decode"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDEy23Y0-Tbd","colab_type":"code","colab":{}},"source":["def prepare_data(aw, ids_to_decode, tokens_to_decode):\n","    out_sen = [None for i in range(len(aw))]\n","    for i in trange(len(aw)):\n","        #topv, topi = aw[i].topk(len(inps_tokens[i]))\n","        topv, topi = aw[i].topk(ids_to_decode[i].index(0))\n","        topi = topi.tolist()\n","        topv = topv.tolist()\n","        #print(i,train_0[i])\n","        #print(tokens_to_decode[i])\n","        #print(\"Original Top Indexes = {}\".format(topi))\n","        topi = [topi[j] for j in range(len(topi)) if ids_to_decode[i][topi[j]] not in not_to_remove_ids] # remove noun and common words\n","        #print(\"After removing Nouns = {}\".format(topi))\n","        topi = [topi[j] for j in range(len(topi)) if \"##\" not in tokens_to_decode[i][topi[j]]] # Remove half words\n","        #print(\"After removing Half-words = {}\".format(topi))\n","\n","        if (len(topi) < 4 and len(topi) > 0):\n","            topi = [topi[0]]\n","        elif(len(topi) < 8):\n","            topi = topi[:2]\n","        else:\n","            topi = topi[:3]\n","\n","        #print(\"Final Topi = {}\".format(topi))\n","        final_indexes = []\n","        count = 0\n","        count1 = 0\n","        #print(ids_to_decode[i], tokens_to_decode[i])\n","        while ids_to_decode[i][count] != 0:\n","            if count in topi:\n","                while ids_to_decode[i][count + count1 + 1] != 0:\n","                    if \"##\" in tokens_to_decode[i][count + count1 + 1]:\n","                        count1 += 1\n","                    else:\n","                        break\n","                count += count1\n","                count1 = 0\n","            else:\n","                final_indexes.append(ids_to_decode[i][count])\n","            count += 1\n","\n","        #print(final_indexes)\n","        temp_out_sen = tokenizer.convert_ids_to_tokens(final_indexes)\n","        temp_out_sen = \" \".join(temp_out_sen).replace(\" ##\", \"\").replace(\"[CLS]\",\"\").replace(\"[SEP]\",\"\")\n","        #print(temp_out_sen, \"\\n\\n\")\n","        out_sen[i] = temp_out_sen.strip()\n","    \n","    return out_sen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dcFzmOC-Tbi","colab_type":"code","colab":{}},"source":["train_0_data = read_file(train_0)\n","train_1_data = read_file(train_1)\n","dev_0_data = read_file(dev_0)\n","dev_1_data = read_file(dev_1)\n","test_0_data = read_file(test_0)\n","test_1_data = read_file(test_1)\n","# not sure what was in the reference files?\n","#ref_0_data = read_file(reference_0)\n","#ref_1_data = read_file(reference_1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWe-DxOh-Tbl","colab_type":"code","outputId":"5dc88f96-2bbe-483d-a966-1e4b1c034717","executionInfo":{"status":"ok","timestamp":1591320706428,"user_tz":420,"elapsed":244200,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_0_data, layer=7, head=0, bs=128)\n","train_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(train_0_data, train_0_out_sen, train_0_out, sentiment=\"<NEG>\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100%|██████████| 78416/78416 [00:19<00:00, 4114.37it/s]\n","100%|██████████| 613/613 [03:39<00:00,  2.79it/s]\n","100%|██████████| 78416/78416 [00:02<00:00, 31101.51it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xOyJRHX7-Tbp","colab_type":"code","outputId":"33d7d491-7434-4996-c79b-6f2cf07e8679","executionInfo":{"status":"ok","timestamp":1591321037597,"user_tz":420,"elapsed":176236,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_1_data, layer=7, head=0, bs=128)\n","train_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(train_1_data, train_1_out_sen, train_1_out, sentiment=\"<POS>\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["100%|██████████| 55970/55970 [00:14<00:00, 3987.38it/s]\n","100%|██████████| 438/438 [02:37<00:00,  2.78it/s]\n","100%|██████████| 55970/55970 [00:01<00:00, 29949.11it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qMuku2QC-Tbs","colab_type":"code","outputId":"08b04b47-8d02-493a-d13c-a39f63451024","executionInfo":{"status":"ok","timestamp":1591321153301,"user_tz":420,"elapsed":7693,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_0_data, layer=7, head=0, bs=128)\n","dev_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(dev_0_data, dev_0_out_sen, dev_0_out, sentiment=\"<NEG>\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100%|██████████| 1896/1896 [00:00<00:00, 4035.84it/s]\n","100%|██████████| 15/15 [00:05<00:00,  2.85it/s]\n","100%|██████████| 1896/1896 [00:00<00:00, 23483.83it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VZHe20P9-Tbv","colab_type":"code","outputId":"cfb2c0fb-ef1d-492b-8b4d-78af3a86b2ab","executionInfo":{"status":"ok","timestamp":1591321168001,"user_tz":420,"elapsed":7624,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_1_data, layer=7, head=0, bs=128)\n","dev_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(dev_1_data, dev_1_out_sen, dev_1_out, sentiment=\"<POS>\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["100%|██████████| 2103/2103 [00:00<00:00, 3975.27it/s]\n","100%|██████████| 17/17 [00:05<00:00,  2.90it/s]\n","100%|██████████| 2103/2103 [00:00<00:00, 29649.65it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sZKci08Z-Tbz","colab_type":"code","outputId":"603f070c-2698-431a-e294-9290214e9e6f","executionInfo":{"status":"ok","timestamp":1591321176590,"user_tz":420,"elapsed":4900,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_1_data, layer=7, head=0, bs=128)\n","test_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(test_1_data, test_1_out_sen, test_1_out, sentiment=\"<POS>\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["100%|██████████| 518/518 [00:00<00:00, 3900.18it/s]\n","100%|██████████| 5/5 [00:01<00:00,  3.46it/s]\n","100%|██████████| 518/518 [00:00<00:00, 26312.82it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iY8GzemX-Tb1","colab_type":"code","outputId":"170424a8-8c19-4168-f67f-7702d873ada9","executionInfo":{"status":"ok","timestamp":1591321182475,"user_tz":420,"elapsed":3346,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_0_data, layer=7, head=0, bs=128)\n","test_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(test_0_data, test_0_out_sen, test_0_out, sentiment=\"<NEG>\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["100%|██████████| 481/481 [00:00<00:00, 3993.20it/s]\n","100%|██████████| 4/4 [00:01<00:00,  2.98it/s]\n","100%|██████████| 481/481 [00:00<00:00, 21333.43it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ggoJokFj-Tb6","colab_type":"code","outputId":"6314f841-1bd5-419c-f1a3-b4c68df68263","executionInfo":{"status":"ok","timestamp":1590983547591,"user_tz":420,"elapsed":2456,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["##Skip this, since we don't have reference data.\n","\n","aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_1_data, layer=7, head=0, bs=128)\n","ref_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","#create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")\n","#changing from above ^^: ref file takes only processed sentences\n","create_ref_output_file(ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:00<00:00, 3645.43it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.57it/s]\n","100%|██████████| 500/500 [00:00<00:00, 27005.67it/s]\n","100%|██████████| 500/500 [00:00<00:00, 521290.58it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mo6uQ-UA-Tb-","colab_type":"code","outputId":"4ee1a29d-229c-4909-d9e0-19976a5f0ff3","executionInfo":{"status":"ok","timestamp":1590983585035,"user_tz":420,"elapsed":2002,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_0_data, layer=7, head=0, bs=128)\n","ref_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","#create_ref_output_file(ref_0_data, ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")\n","#changing from above ^^: ref file takes only processed sentences\n","create_ref_output_file(ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:00<00:00, 3674.15it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n","100%|██████████| 500/500 [00:00<00:00, 27497.86it/s]\n","100%|██████████| 500/500 [00:00<00:00, 213733.39it/s]\n"],"name":"stderr"}]}]}