{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"BERT_DATA_PREPARATION.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X9LVg4o-viwj","colab_type":"text"},"source":["Note: not able to get this to work... it seems to require a pretrained model setting that I'm not able to replicate\n"]},{"cell_type":"code","metadata":{"id":"OOjYTEnOHZY2","colab_type":"code","outputId":"83f805de-e878-4349-ad9b-6d5a25bdec70","executionInfo":{"status":"ok","timestamp":1590980472682,"user_tz":420,"elapsed":22424,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","#drive.mount('/content/gdrive')\n","\n","drive.mount(\"/content/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4TEWL_OiA0AS","colab_type":"code","outputId":"b91419f7-396b-4e0b-c9d1-8cfa54e8a328","executionInfo":{"status":"ok","timestamp":1590977424815,"user_tz":420,"elapsed":2987,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":350}},"source":["#!pip install pytorch-pretrained-bert"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.0+cu101)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.13.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.16.13)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.13->boto3->pytorch-pretrained-bert) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2x6cuLESqgAv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"2f94d630-931a-4d05-a3aa-3c4fc3ab6287","executionInfo":{"status":"ok","timestamp":1590980479635,"user_tz":420,"elapsed":1034,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["import sys\n","print(sys.path)\n","#from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE"],"execution_count":2,"outputs":[{"output_type":"stream","text":["['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"18y9m_ri-TaQ","colab_type":"code","outputId":"d60c71ae-a8f8-4a21-dd4e-0255d827a5d2","executionInfo":{"status":"ok","timestamp":1590980526128,"user_tz":420,"elapsed":19218,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import csv\n","import logging\n","import os\n","import random\n","import sys\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm, trange\n","\n","#load the forked \"pretrained_bert_model\" settings included in the drg repo (use this for bertviz stuff too...)\n","drg_repo_path = '/content/gdrive/My Drive/humor_style_transfer/transformer-drg-style-transfer'\n","if not drg_repo_path in sys.path:\n","  sys.path.append(drg_repo_path)\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n","#from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear #(NOTE: IN THE NEWEST VERSION, 'WARMUP_LINEAR' = ARG FOR BERTADAM)\n","\n","# this part was misbehaving in earlier versions.\n","from bertviz.bertviz import attention, visualization\n","from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"79dO4ZHi-Taa","colab_type":"code","colab":{}},"source":["logger = logging.getLogger(__name__)\n","bert_classifier_model_dir = \"./bert_classifier/\" ## Path of BERT classifier model path (unavailable ???)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OlxUXJLj-Tak","colab_type":"code","colab":{}},"source":["# file paths\n","data_dir = \"./gdrive/My Drive/humor_style_transfer/style-transfer-data/Sentiment-and-Style-Transfer/data\"\n","dataset = \"yelp\" # amazon / yelp / imagecaption\n","train_0 = os.path.join(data_dir ,\"./{}/sentiment.train.0\".format(dataset))\n","train_1 = os.path.join(data_dir,\"./{}/sentiment.train.1\".format(dataset))\n","test_0 = os.path.join(data_dir,\"./{}/sentiment.test.0\".format(dataset))\n","test_1 = os.path.join(data_dir,\"./{}/sentiment.test.1\".format(dataset))\n","dev_0 = os.path.join(data_dir,\"./{}/sentiment.dev.0\".format(dataset))\n","dev_1 = os.path.join(data_dir,\"./{}/sentiment.dev.1\".format(dataset))\n","reference_0 = os.path.join(data_dir,\"./{}/reference.0\".format(dataset))\n","reference_1 = os.path.join(data_dir,\"./{}/reference.1\".format(dataset))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwCOW9eX-Taq","colab_type":"code","colab":{}},"source":["# file paths\n","data_dir = \"./gdrive/My Drive/humor_style_transfer/style-transfer-data/Sentiment-and-Style-Transfer/data\"\n","dataset = \"yelp\" # amazon / yelp / imagecaption\n","train_0_out = os.path.join(data_dir ,\"./{}/processed_files_with_bert_with_best_head/sentiment.train.0\".format(dataset))\n","train_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment.train.1\".format(dataset))\n","test_0_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment.test.0\".format(dataset))\n","test_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment.test.1\".format(dataset))\n","dev_0_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment.dev.0\".format(dataset))\n","dev_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/sentiment.dev.1\".format(dataset))\n","reference_0_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/reference.0\".format(dataset))\n","reference_1_out = os.path.join(data_dir,\"./{}/processed_files_with_bert_with_best_head/reference.1\".format(dataset))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvdP_xyE-Taw","colab_type":"code","outputId":"7c3ea6cd-157a-41c4-a63c-03a74b6003e2","executionInfo":{"status":"ok","timestamp":1590980579283,"user_tz":420,"elapsed":35521,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## Model for performing Classification\n","\n","#[use this after pretrained model found?]\n","#model_cls = BertForSequenceClassification.from_pretrained(bert_classifier_model_dir, num_labels=2) \n","\n","#I think this is downloading bert model - save it later.\n","model_cls = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","model_cls.to(device)\n","model_cls.eval()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 407873900/407873900 [00:14<00:00, 28512982.99B/s]\n","100%|██████████| 231508/231508 [00:00<00:00, 614685.85B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"uXfyUn-3-Ta3","colab_type":"code","outputId":"f650fdda-4fc1-4052-9883-98fd519a6ee0","executionInfo":{"status":"ok","timestamp":1590980615625,"user_tz":420,"elapsed":7432,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## Model to get the attention weights of all the heads\n","\n","### === the below seems not to be working properly... I don't understand what the required output format should be ===\n","#model = BertModel.from_pretrained(bert_classifier_model_dir)\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","model.to(device)\n","model.eval()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Q-yE15HB-Ta8","colab_type":"code","colab":{}},"source":["max_seq_len=70 # Maximum sequence length \n","sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVhKt-A3-TbB","colab_type":"code","colab":{}},"source":["common_words=['is','are','was','were','has','have','had','a','an','the','this','that','these','those','there','how','i','we',\n","             'he','she','it','they','them','their','his','him','her','us','our', 'and','in','my','your','you', 'will', 'shall']\n","common_words_tokens = tokenizer.convert_tokens_to_ids(common_words)\n","not_to_remove_ids = tokenizer.convert_tokens_to_ids([\"[CLS]\",\"[SEP]\", \".\", \"?\", \"!\"])\n","not_to_remove_ids += common_words_tokens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YeiKl0q-TbF","colab_type":"code","colab":{}},"source":["def read_file(file_path):\n","    with open(file_path) as fp:\n","        data = fp.read().splitlines()\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OP1rAcjw-TbK","colab_type":"code","colab":{}},"source":["def create_output_file(original_sentences,processed_sentences, output_file, sentiment=\"<POS>\"):\n","    with open(output_file,\"w\") as fp:\n","        for sen1,sen2 in zip(original_sentences,processed_sentences):\n","            if sen1 != None and sen2 != None:\n","                str1 = sentiment + \" <CON_START> \" + sen2 + \" <START> \" + sen1 + \" <END>\\n\"\n","                fp.write(str1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-pkK_yJ-TbO","colab_type":"code","colab":{}},"source":["#call from lower part: #create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")\n","def create_ref_output_file(processed_sentences, output_file, sentiment=\"<POS>\"):\n","    with open(output_file,\"w\") as fp:\n","        for sen in tqdm(processed_sentences):\n","            if sen != None:\n","                str1 = sentiment + \" <CON_START> \" + sen + \" <START>\\n\"\n","                fp.write(str1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f9itaVL-TbT","colab_type":"code","colab":{}},"source":["def concate_files(inp_files, out_files):\n","    with open(out_files,\"w\") as fp:\n","        for file in inp_files:\n","            with open(file) as f:\n","                for line in f:\n","                    fp.write(line)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G6riNArw-TbY","colab_type":"code","colab":{}},"source":["def run_attn_examples(input_sentences, layer, head, bs=128):\n","    \"\"\"\n","    Returns Attention weights for selected Layer and Head along with ids and tokens\n","    of the input_sentence\n","    \"\"\"\n","    ids = []\n","    ids_to_decode = [None for k in range(len(input_sentences))]\n","    tokens_to_decode = [None for k in range(len(input_sentences))]\n","    segment_ids = []\n","    input_masks = []\n","    attention_weights = [None for z in input_sentences]\n","    ## BERT pre-processing\n","    for j,sen in enumerate(tqdm(input_sentences)):\n","        \n","        text_tokens = tokenizer.tokenize(sen)\n","        if len(text_tokens) >= max_seq_len-2:\n","            text_tokens = text_tokens[:max_seq_len-4]\n","        tokens = [\"[CLS]\"] + text_tokens + [\"[SEP]\"]\n","        tokens_to_decode[j] = tokens\n","        temp_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        ids_to_decode[j] = temp_ids\n","        input_mask = [1] * len(temp_ids)\n","        segment_id = [0] * len(temp_ids)\n","        padding = [0] * (max_seq_len - len(temp_ids))\n","        \n","        \n","        temp_ids += padding\n","        input_mask += padding\n","        segment_id += padding\n","        \n","        ids.append(temp_ids)\n","        input_masks.append(input_mask)\n","        segment_ids.append(segment_id)\n","    \n","    # Convert Ids to Torch Tensors\n","    ids = torch.tensor(ids) \n","    segment_ids = torch.tensor(segment_ids)\n","    input_masks = torch.tensor(input_masks)\n","    \n","    steps = len(ids) // bs\n","    \n","    for i in trange(steps+1):\n","        if i == steps:\n","            temp_ids = ids[i * bs : len(ids)]\n","            temp_segment_ids = segment_ids[i * bs: len(ids)]\n","            temp_input_masks = input_masks[i * bs: len(ids)]\n","        else:\n","            temp_ids = ids[i * bs : i * bs + bs]\n","            temp_segment_ids = segment_ids[i * bs: i * bs + bs]\n","            temp_input_masks = input_masks[i * bs: i * bs + bs]\n","        \n","        temp_ids = temp_ids.to(device)\n","        temp_segment_ids = temp_segment_ids.to(device)\n","        temp_input_masks = temp_input_masks.to(device)\n","        with torch.no_grad():\n","          _, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n","          #WARNING: changed model; produces 2 outputs not 3 (???)\n","            ## what does the below do ??\n","             #_, _, attn = model(temp_ids, temp_segment_ids, temp_input_masks)\n","        # Concate Attention weights\n","        for j in range(len(attn[layer]['attn_probs'])):\n","            attention_weights[i * bs + j] = (attn[layer]['attn_probs'][j][head][0]).to('cpu')\n","    \n","    return attention_weights, ids_to_decode, tokens_to_decode"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDEy23Y0-Tbd","colab_type":"code","colab":{}},"source":["def prepare_data(aw, ids_to_decode, tokens_to_decode):\n","    out_sen = [None for i in range(len(aw))]\n","    for i in trange(len(aw)):\n","        #topv, topi = aw[i].topk(len(inps_tokens[i]))\n","        topv, topi = aw[i].topk(ids_to_decode[i].index(0))\n","        topi = topi.tolist()\n","        topv = topv.tolist()\n","        #print(i,train_0[i])\n","        #print(tokens_to_decode[i])\n","        #print(\"Original Top Indexes = {}\".format(topi))\n","        topi = [topi[j] for j in range(len(topi)) if ids_to_decode[i][topi[j]] not in not_to_remove_ids] # remove noun and common words\n","        #print(\"After removing Nouns = {}\".format(topi))\n","        topi = [topi[j] for j in range(len(topi)) if \"##\" not in tokens_to_decode[i][topi[j]]] # Remove half words\n","        #print(\"After removing Half-words = {}\".format(topi))\n","\n","        if (len(topi) < 4 and len(topi) > 0):\n","            topi = [topi[0]]\n","        elif(len(topi) < 8):\n","            topi = topi[:2]\n","        else:\n","            topi = topi[:3]\n","\n","        #print(\"Final Topi = {}\".format(topi))\n","        final_indexes = []\n","        count = 0\n","        count1 = 0\n","        #print(ids_to_decode[i], tokens_to_decode[i])\n","        while ids_to_decode[i][count] != 0:\n","            if count in topi:\n","                while ids_to_decode[i][count + count1 + 1] != 0:\n","                    if \"##\" in tokens_to_decode[i][count + count1 + 1]:\n","                        count1 += 1\n","                    else:\n","                        break\n","                count += count1\n","                count1 = 0\n","            else:\n","                final_indexes.append(ids_to_decode[i][count])\n","            count += 1\n","\n","        #print(final_indexes)\n","        temp_out_sen = tokenizer.convert_ids_to_tokens(final_indexes)\n","        temp_out_sen = \" \".join(temp_out_sen).replace(\" ##\", \"\").replace(\"[CLS]\",\"\").replace(\"[SEP]\",\"\")\n","        #print(temp_out_sen, \"\\n\\n\")\n","        out_sen[i] = temp_out_sen.strip()\n","    \n","    return out_sen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dcFzmOC-Tbi","colab_type":"code","colab":{}},"source":["train_0_data = read_file(train_0)\n","train_1_data = read_file(train_1)\n","dev_0_data = read_file(dev_0)\n","dev_1_data = read_file(dev_1)\n","test_0_data = read_file(test_0)\n","test_1_data = read_file(test_1)\n","ref_0_data = read_file(reference_0)\n","ref_1_data = read_file(reference_1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWe-DxOh-Tbl","colab_type":"code","outputId":"55ff37b3-d204-4d18-bb21-637a030bbe44","executionInfo":{"status":"ok","timestamp":1590981171529,"user_tz":420,"elapsed":417551,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_0_data, layer=9, head=7, bs=128)\n","train_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(train_0_data, train_0_out_sen, train_0_out, sentiment=\"<NEG>\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["100%|██████████| 177218/177218 [00:23<00:00, 7407.37it/s]\n","100%|██████████| 1385/1385 [06:26<00:00,  3.59it/s]\n","100%|██████████| 177218/177218 [00:04<00:00, 42972.92it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xOyJRHX7-Tbp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"9c6fdfdb-4cd9-4082-8be9-df88640a4b65","executionInfo":{"status":"ok","timestamp":1590981858771,"user_tz":420,"elapsed":624430,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(train_1_data, layer=9, head=7, bs=128)\n","train_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(train_1_data, train_1_out_sen, train_1_out, sentiment=\"<POS>\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100%|██████████| 266041/266041 [00:35<00:00, 7582.41it/s]\n","100%|██████████| 2079/2079 [09:39<00:00,  3.59it/s]\n","100%|██████████| 266041/266041 [00:05<00:00, 47816.04it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qMuku2QC-Tbs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"7db07fdf-493f-43c8-e576-2738b0ced36a","executionInfo":{"status":"ok","timestamp":1590981961166,"user_tz":420,"elapsed":6177,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_0_data, layer=9, head=7, bs=128)\n","dev_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(dev_0_data, dev_0_out_sen, dev_0_out, sentiment=\"<NEG>\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:00<00:00, 7221.06it/s]\n","100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n","100%|██████████| 2000/2000 [00:00<00:00, 40827.83it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VZHe20P9-Tbv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"540d648f-a62a-4073-c934-bab11f3f021f","executionInfo":{"status":"ok","timestamp":1590981973248,"user_tz":420,"elapsed":5611,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(dev_1_data, layer=9, head=7, bs=128)\n","dev_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(dev_1_data, dev_1_out_sen, dev_1_out, sentiment=\"<POS>\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:00<00:00, 8042.45it/s]\n","100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n","100%|██████████| 2000/2000 [00:00<00:00, 38621.76it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sZKci08Z-Tbz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"cb577f15-39ca-4437-cc1f-0d86e71b9314","executionInfo":{"status":"ok","timestamp":1590981982185,"user_tz":420,"elapsed":2053,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_1_data, layer=9, head=7, bs=128)\n","test_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(test_1_data, test_1_out_sen, test_1_out, sentiment=\"<POS>\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:00<00:00, 6603.44it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.64it/s]\n","100%|██████████| 500/500 [00:00<00:00, 32420.49it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iY8GzemX-Tb1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"e5bcc7d2-93e5-4fa2-ec44-1fd2fd3930c4","executionInfo":{"status":"ok","timestamp":1590981989261,"user_tz":420,"elapsed":2219,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(test_0_data, layer=9, head=7, bs=128)\n","test_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","create_output_file(test_0_data, test_0_out_sen, test_0_out, sentiment=\"<NEG>\")"],"execution_count":23,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:00<00:00, 6386.79it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.65it/s]\n","100%|██████████| 500/500 [00:00<00:00, 33033.82it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ggoJokFj-Tb6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"6314f841-1bd5-419c-f1a3-b4c68df68263","executionInfo":{"status":"ok","timestamp":1590983547591,"user_tz":420,"elapsed":2456,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_1_data, layer=9, head=7, bs=128)\n","ref_1_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","#create_ref_output_file(ref_1_data, ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")\n","#changing from above ^^: ref file takes only processed sentences\n","create_ref_output_file(ref_1_out_sen, reference_1_out, sentiment=\"<NEG>\")"],"execution_count":25,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:00<00:00, 3645.43it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.57it/s]\n","100%|██████████| 500/500 [00:00<00:00, 27005.67it/s]\n","100%|██████████| 500/500 [00:00<00:00, 521290.58it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mo6uQ-UA-Tb-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"4ee1a29d-229c-4909-d9e0-19976a5f0ff3","executionInfo":{"status":"ok","timestamp":1590983585035,"user_tz":420,"elapsed":2002,"user":{"displayName":"SIDHARTH DHAWAN","photoUrl":"","userId":"04047089348719294795"}}},"source":["aw, ids_to_decode, tokens_to_decode = run_attn_examples(ref_0_data, layer=9, head=7, bs=128)\n","ref_0_out_sen = prepare_data(aw, ids_to_decode, tokens_to_decode)\n","#create_ref_output_file(ref_0_data, ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")\n","#changing from above ^^: ref file takes only processed sentences\n","create_ref_output_file(ref_0_out_sen, reference_0_out, sentiment=\"<POS>\")"],"execution_count":26,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [00:00<00:00, 3674.15it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n","100%|██████████| 500/500 [00:00<00:00, 27497.86it/s]\n","100%|██████████| 500/500 [00:00<00:00, 213733.39it/s]\n"],"name":"stderr"}]}]}